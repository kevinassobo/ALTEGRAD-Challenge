{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import sys\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths where we will save the datasets\n",
    "data_folder = \"../data\"\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "  data_folder = \"/content/drive/MyDrive/Colab Notebooks/ALTeGraD/Projet/data\"\n",
    "  \n",
    "datasets_folder = os.path.join(data_folder, \"datasets\")\n",
    "models_folder = os.path.join(data_folder, \"models\")\n",
    "\n",
    "train_edges_path = os.path.join(datasets_folder, 'train_graph_edgelist.txt')\n",
    "train_pairs_path = os.path.join(datasets_folder, 'train_pairs.csv')\n",
    "train_target_path = os.path.join(datasets_folder, 'train_target.csv')\n",
    "\n",
    "test_edges_path = os.path.join(datasets_folder, 'test_graph_edgelist.txt')\n",
    "test_pairs_path = os.path.join(datasets_folder, 'test_pairs.csv')\n",
    "test_target_path = os.path.join(datasets_folder, 'test_target.csv')\n",
    "\n",
    "node2vec_train_path = os.path.join(models_folder, 'node2vec_train_graph.model')\n",
    "node2vec_test_path = os.path.join(models_folder, 'node2vec_test_graph.model')\n",
    "node2vec_full_graph_path = os.path.join(models_folder, 'node2vec_full_graph.nodevectors')\n",
    "\n",
    "doc2vec_path = os.path.join(models_folder, \"doc2vec_dm_64.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "train_pairs = pd.read_csv(train_pairs_path, names=['node_1', 'node_2'])\n",
    "train_target = pd.read_csv(train_target_path, names=['target']).to_numpy().ravel()\n",
    "\n",
    "test_pairs = pd.read_csv(test_pairs_path, names=['node_1', 'node_2'])\n",
    "test_target = pd.read_csv(test_target_path, names=['target']).to_numpy().ravel()\n",
    "\n",
    "challenge_pairs = pd.read_csv(\"../data/initial_data/test.txt\", names=['node_1', 'node_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training graph\n",
    "train_graph = nx.read_edgelist(train_edges_path, delimiter=',', nodetype=int)\n",
    "\n",
    "# Load the test graph\n",
    "test_graph = nx.read_edgelist(test_edges_path, delimiter=',', nodetype=int)\n",
    "\n",
    "# Load the full graph\n",
    "graph = nx.read_edgelist(\"../data/initial_data/edgelist.txt\", delimiter=',', nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the abstract of each paper\n",
    "abstracts = dict()\n",
    "with open('../data/initial_data/abstracts.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        node, abstract = line.split('|--|')\n",
    "        abstracts[int(node)] = abstract\n",
    "\n",
    "# Read the authors to each paper\n",
    "authors = dict()\n",
    "with open('../data/authors_processed/authors_ids.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        node, node_authors = line.rstrip('\\n').split('|--|')\n",
    "        authors[int(node)] = node_authors.split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Doc2vec model\n",
    "doc2vec_model = Doc2Vec.load(doc2vec_path)\n",
    "\n",
    "# Read nodes embeddings\n",
    "node2vec_train = KeyedVectors.load_word2vec_format(node2vec_train_path)\n",
    "node2vec_test = KeyedVectors.load_word2vec_format(node2vec_test_path)\n",
    "node2vec_full_graph = KeyedVectors.load_word2vec_format(node2vec_full_graph_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function to compute the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Semantic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Cosine similarity of abstract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_doc2vec(paper_1, paper_2):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between the abstract embeddings of two papers/nodes.\n",
    "    \"\"\"\n",
    "    # The model was trained on all the papers \n",
    "    return doc2vec_model.docvecs.similarity(paper_1, paper_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Attribute Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of common authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_authors(paper_1, paper_2):\n",
    "    \"\"\"\n",
    "    Computes the number of common author between two papers/nodes.\n",
    "    \"\"\"\n",
    "    # The model was trained on all the papers \n",
    "    return len(set(authors[paper_1]) & set(authors[paper_2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Topological features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference in degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_diff_degree(node_1, node_2, G):\n",
    "    \"\"\"\n",
    "    Computes the difference in degree of two nodes in a graph.\n",
    "    \"\"\"\n",
    "    return abs(G.degree(node_1) - G.degree(node_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum of degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_degree(node_1, node_2, G):\n",
    "    \"\"\"\n",
    "    Computes the difference in degree of two nodes in a graph.\n",
    "    \"\"\"\n",
    "    return G.degree(node_1) + G.degree(node_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaccard coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coefficient(node_1, node_2, G):\n",
    "    \"\"\"\n",
    "    Computes the jaccard coefficient of two nodes in a graph.\n",
    "    \"\"\"\n",
    "    _, _, coeff = list(nx.jaccard_coefficient(G, [(node_1, node_2)]))[0]\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adamic Adar Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamic_adar_index(node_1, node_2, G):\n",
    "    \"\"\"\n",
    "    Computes the adamic adar index of two nodes in a graph.\n",
    "    \"\"\"\n",
    "    _, _, index = list(nx.adamic_adar_index(G, [(node_1, node_2)]))[0]\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shortest path length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_length(node_1, node_2, G):\n",
    "    \"\"\"\n",
    "    Computes the shortest path length between two nodes in a graph.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        length = nx.shortest_path_length(G, node_1, node_2)\n",
    "    except nx.NetworkXNoPath:\n",
    "        length = -1\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Nodes embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(u, node_vectors):\n",
    "    \"\"\"\n",
    "    Get the embedding of a node from node2vec model.\n",
    "    \"\"\"\n",
    "    return node_vectors[str(u)]\n",
    "\n",
    "def link_examples_to_features(link_examples, node_vectors, binary_operator):\n",
    "    return [\n",
    "        binary_operator(get_embedding(src, node_vectors), get_embedding(dst, node_vectors))\n",
    "        for src, dst in link_examples\n",
    "    ]\n",
    "\n",
    "def operator_hadamard(u, v):\n",
    "    return u * v\n",
    "\n",
    "\n",
    "def operator_l1(u, v):\n",
    "    return np.abs(u - v)\n",
    "\n",
    "\n",
    "def operator_l2(u, v):\n",
    "    return (u - v) ** 2\n",
    "\n",
    "\n",
    "def operator_avg(u, v):\n",
    "    return (u + v) / 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_pairs.copy()\n",
    "X_test = test_pairs.copy()\n",
    "X_challenge = challenge_pairs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(df, G):\n",
    "    df[\"n_common_authors\"] = df.apply(\n",
    "        lambda row: common_authors(row['node_1'], row['node_2']), axis=1\n",
    "    )\n",
    "\n",
    "    df[\"abstract_similarity\"] = df.apply(\n",
    "        lambda row: cosine_similarity_doc2vec(row['node_1'], row['node_2']), axis=1\n",
    "    )\n",
    "\n",
    "    df[\"jaccard_coeff\"] = df.apply(\n",
    "        lambda row: jaccard_coefficient(row['node_1'], row['node_2'], G), axis=1\n",
    "    )\n",
    "\n",
    "    df[\"adamic_adar_index\"] = df.apply(\n",
    "        lambda row: adamic_adar_index(row['node_1'], row['node_2'], G), axis=1\n",
    "    )\n",
    "    \n",
    "    df[\"shortest_path_length\"] = df.apply(\n",
    "        lambda row: shortest_path_length(row['node_1'], row['node_2'], G), axis=1\n",
    "    )\n",
    "\n",
    "    df[\"abs_diff_degree\"] = df.apply(\n",
    "        lambda row: abs_diff_degree(row['node_1'], row['node_2'], G), axis=1\n",
    "    )\n",
    "\n",
    "    df[\"sum_degree\"] = df.apply(\n",
    "        lambda row: sum_degree(row['node_1'], row['node_2'], G), axis=1\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_features(X_train, graph)\n",
    "compute_features(X_test, graph)\n",
    "compute_features(X_challenge, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, log_loss, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>n_common_authors</th>\n",
       "      <th>abstract_similarity</th>\n",
       "      <th>jaccard_coeff</th>\n",
       "      <th>adamic_adar_index</th>\n",
       "      <th>shortest_path_length</th>\n",
       "      <th>abs_diff_degree</th>\n",
       "      <th>sum_degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23960</td>\n",
       "      <td>21336</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15506</td>\n",
       "      <td>41314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2792</td>\n",
       "      <td>37899</td>\n",
       "      <td>2</td>\n",
       "      <td>0.403547</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.180084</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111658</td>\n",
       "      <td>111203</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64879</td>\n",
       "      <td>77131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386424</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.264257</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_1  node_2  n_common_authors  abstract_similarity  jaccard_coeff  \\\n",
       "0   23960   21336                 0             0.079334       0.000000   \n",
       "1   15506   41314                 0             0.173078       0.000000   \n",
       "2    2792   37899                 2             0.403547       0.052632   \n",
       "3  111658  111203                 0             0.436967       0.000000   \n",
       "4   64879   77131                 0             0.386424       0.031250   \n",
       "\n",
       "   adamic_adar_index  shortest_path_length  abs_diff_degree  sum_degree  \n",
       "0           0.000000                     3                9          33  \n",
       "1           0.000000                     4               16          30  \n",
       "2           0.180084                     2                4          20  \n",
       "3           0.000000                     3                0           8  \n",
       "4           0.264257                     2               23          33  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['node_1', 'node_2'], inplace=True)\n",
    "X_test.drop(columns=['node_1', 'node_2'], inplace=True)\n",
    "X_challenge.drop(columns=['node_1', 'node_2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_common_authors</th>\n",
       "      <th>abstract_similarity</th>\n",
       "      <th>jaccard_coeff</th>\n",
       "      <th>adamic_adar_index</th>\n",
       "      <th>shortest_path_length</th>\n",
       "      <th>abs_diff_degree</th>\n",
       "      <th>sum_degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.079334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.173078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.403547</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.180084</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.436967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.386424</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.264257</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_common_authors  abstract_similarity  jaccard_coeff  adamic_adar_index  \\\n",
       "0                 0             0.079334       0.000000           0.000000   \n",
       "1                 0             0.173078       0.000000           0.000000   \n",
       "2                 2             0.403547       0.052632           0.180084   \n",
       "3                 0             0.436967       0.000000           0.000000   \n",
       "4                 0             0.386424       0.031250           0.264257   \n",
       "\n",
       "   shortest_path_length  abs_diff_degree  sum_degree  \n",
       "0                     3                9          33  \n",
       "1                     4               16          30  \n",
       "2                     2                4          20  \n",
       "3                     3                0           8  \n",
       "4                     2               23          33  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the corresponding link embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (349424, 135)\n"
     ]
    }
   ],
   "source": [
    "X_train_node_emb = link_examples_to_features(\n",
    "    train_pairs.to_numpy(),\n",
    "    node2vec_train,\n",
    "    binary_operator=operator_l1\n",
    ")\n",
    "\n",
    "X_train_c = np.concatenate(\n",
    "    (X_train.to_numpy(), np.array(X_train_node_emb)),\n",
    "    axis=1\n",
    ")\n",
    "print(\"Shape of X_train:\", X_train_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (436782, 135)\n"
     ]
    }
   ],
   "source": [
    "X_test_node_emb = link_examples_to_features(\n",
    "    test_pairs.to_numpy(),\n",
    "    node2vec_test,\n",
    "    binary_operator=operator_l1\n",
    ")\n",
    "\n",
    "X_test_c = np.concatenate(\n",
    "    (X_test.to_numpy(), np.array(X_test_node_emb)),\n",
    "    axis=1\n",
    ")\n",
    "print(\"Shape of X_test:\", X_test_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_challenge: (106692, 135)\n"
     ]
    }
   ],
   "source": [
    "X_challenge_node_emb = link_examples_to_features(\n",
    "    challenge_pairs.to_numpy(),\n",
    "    node2vec_full_graph,\n",
    "    binary_operator=operator_l1\n",
    ")\n",
    "\n",
    "X_challenge_c = np.concatenate(\n",
    "    (X_challenge.to_numpy(), np.array(X_challenge_node_emb)),\n",
    "    axis=1\n",
    ")\n",
    "print(\"Shape of X_challenge:\", X_challenge_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_c = np.concatenate((X_train_c, X_test_c))\n",
    "y_new = np.concatenate((train_target, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_new_sc = scaler.fit_transform(X_new_c)\n",
    "X_challenge_sc = scaler.transform(X_challenge_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train_c)\n",
    "X_test_sc = scaler.transform(X_test_c)\n",
    "X_challenge_sc = scaler.transform(X_challenge_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=2000)\n",
    "lr_clf.fit(X_new_sc, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8904744499322637"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_target, lr_clf.predict_proba(X_train_sc)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13622079791101255"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_new, lr_clf.predict_proba(X_new_sc)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13233471812878958"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test_target, lr_clf.predict_proba(X_test_sc)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "y_pred = lr_clf.predict_proba(X_challenge_sc)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "# Write predictions to a file\n",
    "predictions = zip(range(len(y_pred)), y_pred)\n",
    "with open(\"submission.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c13f75b521158b36ba3ff4ac87dceddef9f3d5f34c1f5e4e80e856c73bb49853"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
