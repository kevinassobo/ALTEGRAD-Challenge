{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTHOR & PAPER COLLABORATION NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this notebook are: \n",
    "- assign an ID to each author for easier maniplation\n",
    "- build a dictionnary with authors as keys and the list of their papers as values. \n",
    "- buil an author collaboration graph where nodes represent authors and edges the number of time they co-authored a paper (no node if they never co-authored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "import paths # script with all data paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing of the authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will encode the authors names into identificators so that we can easily manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files already exist !\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(paths.ID_2_AUTHOR_PATH) or \\\n",
    "    not os.path.isfile(paths.PAPER_2_AUTHORS_ID_PATH):\n",
    "    \n",
    "    all_authors = set() # set of all the authors in the dataset\n",
    "    paper_authors = dict() # dictionnary  {paper : list of authors names}\n",
    "    with open(paths.AUTHORS_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            paper, authors = line.rstrip('\\n').split('|--|')\n",
    "            authors = authors.split(',')\n",
    "            paper_authors[int(paper)] = authors\n",
    "            all_authors |= set(authors) # '|' is the union operator\n",
    "\n",
    "\n",
    "    id2author = dict() # dictionnary {author id : author name}\n",
    "    author2id = dict() # dictionnary {author name : author id}\n",
    "    for i, author in enumerate(all_authors):\n",
    "        id2author[i] = author\n",
    "        author2id[author] = i\n",
    "\n",
    "    # Save the (id,name) pairs as a text file\n",
    "    with open(paths.ID_2_AUTHOR_PATH, 'w+') as f: \n",
    "        for id_, author in id2author.items(): \n",
    "            f.write(f\"{id_},{author}\\n\") \n",
    "\n",
    "    # Create a new file similar to authors.txt but with authors ids instead of their names\n",
    "    with open(paths.PAPER_2_AUTHORS_ID_PATH, 'w+') as f: \n",
    "        for paper, authors in paper_authors.items():\n",
    "            authors_id = list(map(author2id.get, authors))\n",
    "            authors_id = list(map(str, authors_id))\n",
    "            f.write(f\"{paper}|--|{','.join(authors_id)}\\n\")\n",
    "else:\n",
    "    print(\"The files already exist !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get all the papers of each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file already exists !\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(paths.AUTHOR_ID_2_PAPERS_PATH):\n",
    "    # {paper : authors ids} dict\n",
    "    paper_authors = dict()\n",
    "    with open(paths.PAPER_2_AUTHORS_ID_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            paper, co_authors = line.rstrip('\\n').split('|--|')\n",
    "            paper_authors[int(paper)] = list(map(int,co_authors.split(',')))\n",
    "\n",
    "    # Build {author id : papers} \n",
    "    author_papers = dict()\n",
    "    for paper, authors in paper_authors.items():\n",
    "        for author in authors:\n",
    "            if author in author_papers:\n",
    "                author_papers[author] += [paper]\n",
    "            else:\n",
    "                author_papers[author] = [paper]\n",
    "\n",
    "    # Create a new file with each line as \"author|--|paper1,paper2,...\"\n",
    "    with open(paths.AUTHOR_ID_2_PAPERS_PATH, 'w+') as f: \n",
    "        for author, papers in author_papers.items():\n",
    "            papers = list(map(str, papers))\n",
    "            f.write(f\"{author}|--|{','.join(papers)}\\n\")\n",
    "else:\n",
    "    print(\"The file already exists !\")\n",
    "    # We just read the file\n",
    "    author_papers = dict()\n",
    "    with open(paths.AUTHOR_ID_2_PAPERS_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            author, papers = line.rstrip('\\n').split('|--|')\n",
    "            author_papers[int(author)] = list(map(int,papers.split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the author collaboration network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create an undirected graph of authors, where two authors are connected by an edge with weight $k$ if there are $k$ papers that they co-authored.\n",
    "\n",
    "We first build the adjacency matrix of this graph as a weighted collaboration matrix $W \\in \\mathbb{R}^{n\\times n}$ (n := number of authors) such that for two authors $i$ and $j$:\n",
    "\n",
    "$$\n",
    "W_{ij} = \\sum_{p \\in papers} \\frac{\\delta^p_i \\delta^p_j}{n_p - 1} \n",
    "\\quad \\text{if} \\quad  i \\neq j \\quad\\quad \\text{and} \\quad\\quad\n",
    "W_{ii} = 0 \n",
    "$$\n",
    "\n",
    "where $n_p$ is the number of authors of paper $p$ and $\\delta^p_i$ = $\\mathbf{1}$($i \\in$ {authors of $p$}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file already exist !\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(paths.AUTHORS_EDGELIST_PATH):\n",
    "    # {paper : authors ids} dict\n",
    "    paper_authors = dict()\n",
    "    with open(paths.PAPER_2_AUTHORS_ID_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            paper, co_authors = line.rstrip('\\n').split('|--|')\n",
    "            paper_authors[int(paper)] = list(map(int,co_authors.split(',')))\n",
    "\n",
    "    # Total number of authors\n",
    "    with open(paths.ID_2_AUTHOR_PATH, 'r') as f:\n",
    "        n_authors = len(f.readlines())\n",
    "    print(\"Number of authors:\", n_authors)\n",
    "\n",
    "    # Adjacency matrix of our future graph\n",
    "    author_collab_weights = np.zeros((n_authors, n_authors))\n",
    "\n",
    "    all_author_collabs = set()\n",
    "    for paper in paper_authors:\n",
    "        # Create tuples of author collaborations for one paper\n",
    "        # itertools.combinations(p, r) creates r-length tuples, in sorted order, no repeated elements\n",
    "        # e.g. : list(itertools.combinations('ABC', 2)) >>> [('A', 'B'), ('A', 'B'), ('B', 'C')] \n",
    "        authors = paper_authors[paper]\n",
    "        author_collabs = list(itertools.combinations(authors, r=2))\n",
    "        all_author_collabs |= set(author_collabs)\n",
    "        for author_1, author_2 in author_collabs:\n",
    "            author_collab_weights[author_1, author_2] += 1/(len(authors)-1)\n",
    "            author_collab_weights[author_2, author_1] += 1/(len(authors)-1)\n",
    "\n",
    "\n",
    "    print(\"# of collabs before the sort:\", len(all_author_collabs))\n",
    "    # We sort each pair of collab because we consider  that \n",
    "    # a collab (author_1, author_2) is the same as a collab (author_2, author_1)\n",
    "    all_author_collabs = list(map(sorted, all_author_collabs))\n",
    "    # The result of sorted is a list so we put it back as a tuple\n",
    "    all_author_collabs = set(map(tuple, all_author_collabs))\n",
    "    print(\"# of collabs after the sort:\", len(all_author_collabs))\n",
    "\n",
    "\n",
    "    # Write the collaborations in a file where each line 'author_1,author_2,n_collabs'\n",
    "    # means that author_1 and author_2 co-authored n_collabs papers\n",
    "    # NOTE: the graph will not contains authors that never collaborated with anyone\n",
    "    with open(paths.AUTHORS_EDGELIST_PATH, 'w+') as f:\n",
    "        for (author_1, author_2) in all_author_collabs:\n",
    "            weight = author_collab_weights[author_1, author_2]\n",
    "            f.write(f\"{author_1},{author_2},{round(weight,2)}\\n\")\n",
    "else:\n",
    "    print(\"The file already exist !\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c13f75b521158b36ba3ff4ac87dceddef9f3d5f34c1f5e4e80e856c73bb49853"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
