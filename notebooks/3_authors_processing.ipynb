{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTHOR NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this notebook are: \n",
    "- assign an ID to each author for easier maniplation\n",
    "- build a dictionnary with authors as keys and the list of their papers as values. \n",
    "- build an **author collaboration graph** where nodes represent authors, two authors have an edges **if they co-authored at least one paper.**\n",
    "- build an **author citation graph** where nodes represent authors, two authors have an edges **if there is at least one time when one of them cited the other one in a paper.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gc\n",
    "import itertools \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import paths # script with all data paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing of the authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will encode the authors names into identificators so that we can easily manipulate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following files will be added in the folder `data/authors_processed`:\n",
    "- `id2author.txt` : contains a line *\"id,name\"* for each author\n",
    "- `paper_2_authors_id.txt` : contains a line *\"paper|--|auth_id_1,auth_id_2,...\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files already exist !\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(paths.ID_2_AUTHOR_PATH) or \\\n",
    "    not os.path.isfile(paths.PAPER_2_AUTHORS_ID_PATH):\n",
    "    \n",
    "    all_authors = set() # set of all the authors in the dataset\n",
    "    paper_authors = dict() # dictionnary  {paper : list of authors names}\n",
    "    with open(paths.AUTHORS_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            paper, authors = line.rstrip('\\n').split('|--|')\n",
    "            authors = authors.split(',')\n",
    "            paper_authors[int(paper)] = authors\n",
    "            all_authors |= set(authors) # '|' is the union operator\n",
    "\n",
    "\n",
    "    id2author = dict() # dictionnary {author id : author name}\n",
    "    author2id = dict() # dictionnary {author name : author id}\n",
    "    for i, author in enumerate(all_authors):\n",
    "        id2author[i] = author\n",
    "        author2id[author] = i\n",
    "\n",
    "    # Save the (id,name) pairs as a text file\n",
    "    with open(paths.ID_2_AUTHOR_PATH, 'w+') as f: \n",
    "        for id_, author in id2author.items(): \n",
    "            f.write(f\"{id_},{author}\\n\") \n",
    "\n",
    "    # Create a new file similar to authors.txt but with authors ids instead of their names\n",
    "    with open(paths.PAPER_2_AUTHORS_ID_PATH, 'w+') as f: \n",
    "        for paper, authors in paper_authors.items():\n",
    "            authors_id = list(map(author2id.get, authors))\n",
    "            authors_id = list(map(str, authors_id))\n",
    "            f.write(f\"{paper}|--|{','.join(authors_id)}\\n\")\n",
    "else:\n",
    "    print(\"The files already exist !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get all the papers of each author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following file will be added in the folder `data/authors_processed`:\n",
    "- `author_id_2_papers.txt` : contains a line *\"author_id|--|paper_1,paper_2,...\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file already exists !\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(paths.AUTHOR_ID_2_PAPERS_PATH):\n",
    "    # {paper : authors ids} dict\n",
    "    paper_authors = dict()\n",
    "    with open(paths.PAPER_2_AUTHORS_ID_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            paper, co_authors = line.rstrip('\\n').split('|--|')\n",
    "            paper_authors[int(paper)] = list(map(int,co_authors.split(',')))\n",
    "\n",
    "    # Build {author id : papers} \n",
    "    author_papers = dict()\n",
    "    for paper, authors in paper_authors.items():\n",
    "        for author in authors:\n",
    "            if author in author_papers:\n",
    "                author_papers[author] += [paper]\n",
    "            else:\n",
    "                author_papers[author] = [paper]\n",
    "\n",
    "    # Create a new file with each line as \"author|--|paper1,paper2,...\"\n",
    "    with open(paths.AUTHOR_ID_2_PAPERS_PATH, 'w+') as f: \n",
    "        for author, papers in author_papers.items():\n",
    "            papers = list(map(str, papers))\n",
    "            f.write(f\"{author}|--|{','.join(papers)}\\n\")\n",
    "else:\n",
    "    print(\"The file already exists !\")\n",
    "    # We just read the file\n",
    "    author_papers = dict()\n",
    "    with open(paths.AUTHOR_ID_2_PAPERS_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            author, papers = line.rstrip('\\n').split('|--|')\n",
    "            author_papers[int(author)] = list(map(int,papers.split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Author collaboration graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following file will be added in the folder `data/authors_processed`:\n",
    "- `author_collab_edgelist.txt` : contain a line *\"author_id_1,author_id_2,weigth\"* for each edge of the author collaboration graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to build the graph ?\n",
    "\n",
    "We want to create a weighted undirected graph of authors, where two authors are connected by an edge if they co-authored at least one paper. Note that This graph is independant from the paper citation graph.\n",
    "\n",
    "We first build the adjacency matrix of this graph as a weighted collaboration matrix $W \\in \\mathbb{R}^{n\\times n}$ (n := number of authors) such that for two authors $i$ and $j$:\n",
    "\n",
    "$$\n",
    "W_{ij} = \\sum_{p\\ \\in\\ papers} \\frac{\\delta^p_i \\delta^p_j}{n_p - 1} \n",
    "\\quad \\text{if} \\quad  i \\neq j \\quad\\quad \\text{and} \\quad\\quad\n",
    "W_{ii} = 0 \n",
    "$$\n",
    "\n",
    "where $n_p$ is the number of authors of paper $p$ and $\\delta^p_i$ = $\\mathbf{1}$($i \\in$ {authors of $p$}).\n",
    "\n",
    "We use this formula so that the weight of a collaboration in a paper is correlated to the number of authors of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: example of the use of itertools.combinations\n",
    "# we will use that to create pairs of co-authors of a paper\n",
    "a = [1, 2, 3, 4]\n",
    "\n",
    "co_auths = list(itertools.combinations(a, r=2))\n",
    "co_auths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file already exist !\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(paths.AUTHCOLL_EDGELIST_PATH):\n",
    "    # {paper : authors ids} dict\n",
    "    paper_authors = dict()\n",
    "    with open(paths.PAPER_2_AUTHORS_ID_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            paper, co_authors = line.rstrip('\\n').split('|--|')\n",
    "            paper_authors[int(paper)] = list(map(int,co_authors.split(',')))\n",
    "\n",
    "    # Total number of authors\n",
    "    with open(paths.ID_2_AUTHOR_PATH, 'r') as f:\n",
    "        n_authors = len(f.readlines())\n",
    "    print(\"Number of authors:\", n_authors)\n",
    "\n",
    "    # Adjacency matrix of our future graph\n",
    "    author_collab_weights = np.zeros((n_authors, n_authors))\n",
    "\n",
    "    all_author_collabs = set()\n",
    "    for paper in paper_authors:\n",
    "        # Create tuples of author citations for one paper\n",
    "        # NOTE: Look at the previous cell to understand the use of itertools.combinations\n",
    "        authors = paper_authors[paper]\n",
    "        author_collabs = list(itertools.combinations(authors, r=2))\n",
    "        all_author_collabs |= set(author_collabs)\n",
    "        for author_1, author_2 in author_collabs:\n",
    "            author_collab_weights[author_1, author_2] += 1/(len(authors)-1)\n",
    "            author_collab_weights[author_2, author_1] += 1/(len(authors)-1)\n",
    "\n",
    "\n",
    "    print(\"# of collabs before the sort:\", len(all_author_collabs))\n",
    "    # We sort each pair of collab because we consider  that \n",
    "    # a collab (author_1, author_2) is the same as a collab (author_2, author_1)\n",
    "    all_author_collabs = list(map(sorted, all_author_collabs))\n",
    "    # The result of sorted is a list so we put it back as a tuple\n",
    "    all_author_collabs = set(map(tuple, all_author_collabs))\n",
    "    print(\"# of collabs after the sort:\", len(all_author_collabs))\n",
    "\n",
    "\n",
    "    # Write the collaborations in a file where each line 'author_1,author_2,n_collabs'\n",
    "    # means that author_1 and author_2 co-authored n_collabs papers\n",
    "    # NOTE: the graph will not contains authors that never collaborated with anyone\n",
    "    print(\"Saving the edgelist ...\")\n",
    "    with open(paths.AUTHCOLL_EDGELIST_PATH, 'w+') as f:\n",
    "        for (author_1, author_2) in all_author_collabs:\n",
    "            weight = author_collab_weights[author_1, author_2]\n",
    "            f.write(f\"{author_1},{author_2},{round(weight,2)}\\n\")\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"The author collaboration graph was already built !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Author citation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following file will be added in the folder `data/authors_citations`:\n",
    "- `authcit_edgelist.txt` : contain a line *\"author_id_1,author_id_2,weigth\"* for each edge of the author citation graph corresponding to the full paper graph\n",
    "- `train_authcit_edgelist.txt` : contain a line *\"author_id_1,author_id_2,weigth\"* for each edge of the author citation graph corresponding to the train paper graph\n",
    "- `test_authcit_edgelist.txt` : contain a line *\"author_id_1,author_id_2,weigth\"* for each edge of the author citation graph corresponding to the test paper graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to build the graph ?\n",
    "\n",
    "We want to create a weighted undirected graph of authors, where two authors are connected by an edge if there is at least one time when one of them cited the other in a paper. Thus we need the paper citation graph. Since we have three paper citation graph, we will build three author citation graph.\n",
    "\n",
    "Consider the paper citation graph $G=(A,E)$. We first build the adjacency matrix of the corresponding author citation graph as a weighted citation matrix $W \\in \\mathbb{R}^{n\\times n}$ (n := number of authors) such that for two authors $i$ and $j$:\n",
    "\n",
    "$$\n",
    "W_{ij} = \\sum_{(p_1,p_2)\\ \\in\\ E} \n",
    "\\frac{\\delta^{p_1}_i \\delta^{p_2}_j}{n_{p_1} n_{p_2}} \n",
    "$$\n",
    "\n",
    "where $n_p$ is the number of authors of paper $p$ and $\\delta^p_i$ = $\\mathbf{1}$($i \\in$ {authors of $p$}).\n",
    "\n",
    "We use this formula so that the weight of a citation is correlated to the number of authors of both papers.\n",
    "\n",
    "Note that we did not put $W_{ii}=0$ because we consider self-citation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers: 138499\n",
      "Number of authors: 149682\n"
     ]
    }
   ],
   "source": [
    "# {paper : authors ids} dict\n",
    "paper_authors = dict()\n",
    "with open(paths.PAPER_2_AUTHORS_ID_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        paper, co_authors = line.rstrip('\\n').split('|--|')\n",
    "        paper_authors[int(paper)] = list(map(int,co_authors.split(',')))\n",
    "\n",
    "print(\"Number of papers:\", len(paper_authors))\n",
    "\n",
    "# Total number of authors\n",
    "with open(paths.ID_2_AUTHOR_PATH, 'r') as f:\n",
    "    n_authors = len(f.readlines())\n",
    "print(\"Number of authors:\", n_authors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 5), (1, 6), (2, 5), (2, 6), (3, 5), (3, 6)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: example of the use of itertools.product\n",
    "# we will use that to create pairs of authors of two papers with an edge\n",
    "a = [1, 2, 3]\n",
    "b = [5, 6]\n",
    "\n",
    "prods = list(itertools.product(a, b))\n",
    "prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_author_citation_graph(paper_edges_path, path_to_save):\n",
    "    \"\"\"\n",
    "    Compute and save the author citation edgelist of the corresponding paper citation graph. \n",
    "    \"\"\"\n",
    "    paper_citation_edges = pd.read_csv(\n",
    "        paper_edges_path,\n",
    "        header=None\n",
    "    ).to_numpy()\n",
    "\n",
    "    # Adjacency matrix of our future graph\n",
    "    author_citation_weights = np.zeros((n_authors, n_authors))\n",
    "\n",
    "    all_author_citations = set()\n",
    "\n",
    "    for paper_1, paper_2 in paper_citation_edges:\n",
    "        # Get the authors of each paper\n",
    "        authors_1 = paper_authors[paper_1]\n",
    "        authors_2 = paper_authors[paper_2]\n",
    "\n",
    "        # Create pairs of author citations\n",
    "        # NOTE: Look at the previous cell to understand the use of itertools.product\n",
    "        author_citations = list(itertools.product(authors_1, authors_2))\n",
    "        all_author_citations |= set(author_citations)\n",
    "\n",
    "        for author_1, author_2 in author_citations:\n",
    "            author_citation_weights[author_1, author_2] += 1 / (len(authors_1) * len(authors_2))\n",
    "            author_citation_weights[author_2, author_1] += 1 / (len(authors_1) * len(authors_2))\n",
    "\n",
    "\n",
    "    print(\"# of authors citation before the sort:\", len(all_author_citations))\n",
    "    # We sort each pair of citation because we consider  that \n",
    "    # a citation (author_1, author_2) is the same as a citation (author_2, author_1)\n",
    "    all_author_citations = list(map(sorted, all_author_citations))\n",
    "    # The result of sorted is a list so we put it back as a tuple\n",
    "    all_author_citations = set(map(tuple, all_author_citations))\n",
    "    print(\"# of authors citation after the sort:\", len(all_author_citations))\n",
    "\n",
    "    # Save the edgelist to path\n",
    "    print(\"Saving the edgelist ...\")\n",
    "    with open(path_to_save, 'w+') as f:\n",
    "        for (author_1, author_2) in all_author_citations:\n",
    "            weight = author_citation_weights[author_1, author_2]\n",
    "            f.write(f\"{author_1},{author_2},{round(weight,2)}\\n\")\n",
    "    print(\"Done\")\n",
    "\n",
    "    del all_author_citations, author_citation_weights\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author citation graph corresponding to the full paper graph was already built !\n"
     ]
    }
   ],
   "source": [
    "# Full paper citation graph\n",
    "if not os.path.isfile(paths.FULL_AUTHCIT_EDGELIST_PATH):\n",
    "    build_author_citation_graph(\n",
    "        paths.FULL_GRAPH_EDGELIST_PATH, \n",
    "        paths.FULL_AUTHCIT_EDGELIST_PATH\n",
    "    )\n",
    "else:\n",
    "    print(\"The author citation graph corresponding to the full paper graph was already built !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author citation graph corresponding to the train paper graph was already built !\n"
     ]
    }
   ],
   "source": [
    "# Train paper citation graph\n",
    "if not os.path.isfile(paths.TRAIN_AUTHCIT_EDGELIST_PATH):\n",
    "    build_author_citation_graph(\n",
    "        paths.TRAIN_EDGELIST_PATH,\n",
    "        paths.TRAIN_AUTHCIT_EDGELIST_PATH\n",
    "    )\n",
    "else:\n",
    "    print(\"The author citation graph corresponding to the train paper graph was already built !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author citation graph corresponding to the test paper graph was already built !\n"
     ]
    }
   ],
   "source": [
    "# Test paper citation graph\n",
    "if not os.path.isfile(paths.TEST_AUTHCIT_EDGELIST_PATH):\n",
    "    build_author_citation_graph(\n",
    "        paths.TEST_EDGELIST_PATH,\n",
    "        paths.TEST_AUTHCIT_EDGELIST_PATH\n",
    "    )\n",
    "else:\n",
    "    print(\"The author citation graph corresponding to the test paper graph was already built !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c13f75b521158b36ba3ff4ac87dceddef9f3d5f34c1f5e4e80e856c73bb49853"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
