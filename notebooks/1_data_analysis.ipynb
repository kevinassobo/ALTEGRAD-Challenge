{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS OF THE PAPER CITATION NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analysis of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist('../data/initial_data/edgelist.txt', delimiter=',', nodetype=int)\n",
    "nodes = list(G.nodes())\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "print('Number of nodes:', n)\n",
    "print('Number of edges:', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pairs_test = list()\n",
    "with open('../data/initial_data/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        node_pairs_test.append((int(t[0]), int(t[1])))\n",
    "\n",
    "node_pairs_test = list(map(sorted, node_pairs_test))\n",
    "# The result of sorted is a list so we put it back as a tuple\n",
    "node_pairs_test = list(map(tuple, node_pairs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(G.edges())\n",
    "\n",
    "edges = list(map(sorted, edges))\n",
    "# The result of sorted is a list so we put it back as a tuple\n",
    "edges = list(map(tuple, edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(edges) & set(node_pairs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that none of the node pairs of the test set are not edges in the graph. We don't know if there is a citation link between each node pair of the test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the non-edges pairs of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-edges will be the instances of our training dataset of the negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_edges_path = \"../data/datasets/list_non_edges.pkl\"\n",
    "\n",
    "if not os.path.isfile(non_edges_path):\n",
    "    random.seed(12)\n",
    "    non_edges = [(random.randint(0, n-1), random.randint(0, n-1)) for _ in range(m+1000)]\n",
    "\n",
    "    non_edges = list(map(sorted, non_edges))\n",
    "    # The result of sorted is a list so we put it back as a tuple\n",
    "    non_edges = list(map(tuple, non_edges))\n",
    "\n",
    "    # Remove edges or node pairs in the test set\n",
    "    non_edges = set(non_edges) - (set(node_pairs_test) | set(edges))\n",
    "\n",
    "    def check_shortest_path_length(G, a, b):\n",
    "        try:\n",
    "            res = nx.shortest_path_length(G,a,b) > 2\n",
    "        except nx.NetworkXNoPath:\n",
    "            res = True\n",
    "        return res\n",
    "\n",
    "    # Remove pairs for which shortest path > 2\n",
    "    non_edges = [\n",
    "        (a,b) for a,b in non_edges\n",
    "        if check_shortest_path_length(G,a,b)\n",
    "    ]\n",
    "\n",
    "    # Save the non edges\n",
    "    with open(non_edges_path, 'wb') as f:\n",
    "        pickle.dump(non_edges, f)\n",
    "\n",
    "else:\n",
    "    # Read the non edges\n",
    "    with open(non_edges_path, 'rb') as f:\n",
    "        non_edges = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"../data/datasets/train_set\"\n",
    "test_folder = \"../data/datasets/test_set\"\n",
    "\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "train_edges_path = os.path.join(train_folder, 'train_edges.csv')\n",
    "train_non_edges_path = os.path.join(train_folder, 'train_non_edges.csv')\n",
    "train_path = os.path.join(train_folder, 'train.csv')\n",
    "train_y_path = os.path.join(train_folder, 'train_y.csv')\n",
    "\n",
    "test_edges_path = os.path.join(test_folder, 'test_edges.csv')\n",
    "test_non_edges_path = os.path.join(test_folder, 'test_non_edges.csv')\n",
    "test_path = os.path.join(test_folder, 'test.csv')\n",
    "test_y_path = os.path.join(test_folder, 'test_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs of node in the graph with edges 1091955\n",
      "Number of pairs of node in the graph without edges 1084146\n",
      "============================================================\n",
      "Number of pairs of node in the train data graph with edges 873564\n",
      "Number of pairs of node in the train data graph without edges 867316\n",
      "============================================================\n",
      "Number of pairs of node in the test data graph with edges 218391\n",
      "Number of pairs of node in the test data graph without edges 216830\n"
     ]
    }
   ],
   "source": [
    "if (not os.path.isfile(train_edges_path)) and (not os.path.isfile(test_edges_path)):\n",
    "    # Positive links\n",
    "    df_edges = pd.read_csv(\"../data/initial_data/edgelist.txt\", names=['node_1', 'node_2'])\n",
    "    # negative links\n",
    "    df_non_edges = pd.DataFrame(non_edges, columns=['node_1', 'node_2'])\n",
    "    \n",
    "    print(\"Number of pairs of node in the graph with edges\", df_edges.shape[0])\n",
    "    print(\"Number of pairs of node in the graph without edges\", df_non_edges.shape[0])\n",
    "    \n",
    "    #Trian test split \n",
    "    #Spiltted data into 80-20 \n",
    "    #positive links and negative links seperatly because we need positive training data only for creating graph \n",
    "    #and for feature generation\n",
    "    X_train_pos, X_test_pos, y_train_pos, y_test_pos  = train_test_split(\n",
    "        df_edges, np.ones(len(df_edges)), test_size=0.2, random_state=12\n",
    "    )\n",
    "    X_train_neg, X_test_neg, y_train_neg, y_test_neg  = train_test_split(\n",
    "        df_non_edges, np.zeros(len(df_non_edges)), test_size=0.2, random_state=12\n",
    "    )\n",
    "    \n",
    "    print('='*60)\n",
    "    print(\"Number of pairs of node in the train data graph with edges\", X_train_pos.shape[0])\n",
    "    print(\"Number of pairs of node in the train data graph without edges\", X_train_neg.shape[0])\n",
    "    print('='*60)\n",
    "    print(\"Number of pairs of node in the test data graph with edges\", X_test_pos.shape[0])\n",
    "    print(\"Number of pairs of node in the test data graph without edges\", X_test_neg.shape[0])\n",
    "\n",
    "    #removing header and saving\n",
    "    X_train_pos.to_csv(train_edges_path, header=False, index=False)\n",
    "    X_test_pos.to_csv(test_edges_path, header=False, index=False)\n",
    "    X_train_neg.to_csv(train_non_edges_path, header=False, index=False)\n",
    "    X_test_neg.to_csv(test_non_edges_path, header=False, index=False)\n",
    "\n",
    "del non_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of common papers in train and test (edgelists): 100935\n",
      "# of papers present in train but not in test (edgelists): 34561\n",
      "# of papers present in test but not in train (edgelists): 3003\n",
      "Percentage in test of papers not in train (edgelists) is     2.89%\n"
     ]
    }
   ],
   "source": [
    "# Graph of train set\n",
    "train_graph = nx.read_edgelist(train_edges_path, delimiter=',', nodetype=int)\n",
    "# Graph of test set\n",
    "test_graph = nx.read_edgelist(test_edges_path, delimiter=',', nodetype=int)\n",
    "\n",
    "# finding the unique nodes in the both train and test graphs\n",
    "train_nodes_pos = set(train_graph.nodes())\n",
    "test_nodes_pos = set(test_graph.nodes())\n",
    "\n",
    "trY_teY = len(train_nodes_pos.intersection(test_nodes_pos))\n",
    "trY_teN = len(train_nodes_pos - test_nodes_pos)\n",
    "teY_trN = len(test_nodes_pos - train_nodes_pos)\n",
    "\n",
    "print('# of common papers in train and test (edgelists):', trY_teY)\n",
    "print('# of papers present in train but not in test (edgelists):', trY_teN)\n",
    "\n",
    "print('# of papers present in test but not in train (edgelists):', teY_trN)\n",
    "print(f\"Percentage in test of papers not in train (edgelists) is \\\n",
    "    {teY_trN/len(test_nodes_pos)*100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a cold start problem here because some nodes present in the the test graph are not in the train graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c13f75b521158b36ba3ff4ac87dceddef9f3d5f34c1f5e4e80e856c73bb49853"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
