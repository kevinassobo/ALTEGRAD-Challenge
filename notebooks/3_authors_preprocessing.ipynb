{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTHOR COLLABORATION NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to build an author collaboration graph and extract some features from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing of the authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will encode the authors names into identificators so that we can easily manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors = set() # set of all the authors in the dataset\n",
    "node_authors = dict() # dictionnary  {node/paper : list of authors names}\n",
    "with open(\"../data/initial_data/authors.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        node, authors = line.rstrip('\\n').split('|--|')\n",
    "        authors = authors.split(',')\n",
    "        node_authors[int(node)] = authors\n",
    "        all_authors |= set(authors) # '|' is the union operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2author = dict() # dictionnary {author id : author name}\n",
    "author2id = dict() # dictionnary {author name : author id}\n",
    "for i, author in enumerate(all_authors):\n",
    "    id2author[i] = author\n",
    "    author2id[author] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the (id,name) pairs as a text file\n",
    "with open(\"../data/authors_processed/id2author.txt\", 'w+') as f: \n",
    "    for id_, author in id2author.items(): \n",
    "        f.write(f\"{id_},{author}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new file similar to authors.txt but with authors ids instead of their names\n",
    "with open(\"../data/authors_processed/authors_ids.txt\", 'w+') as f: \n",
    "    for node, authors in node_authors.items():\n",
    "        authors_id = list(map(author2id.get, authors))\n",
    "        authors_id = list(map(str, authors_id))\n",
    "        f.write(f\"{node}|--|{','.join(authors_id)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the author collaboration network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create an undirected graph of authors, where two authors are connected by an edge with weight $k$ if there are $k$ papers that they co-authored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle \n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper - authors ids dict\n",
    "paper_authors = dict()\n",
    "with open('../data/authors_processed/authors_ids.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        node, node_authors = line.rstrip('\\n').split('|--|')\n",
    "        paper_authors[int(node)] = list(map(int,node_authors.split(',')))\n",
    "\n",
    "# Number of authors\n",
    "with open(\"../data/authors_processed/id2author.txt\", 'r') as f:\n",
    "    n_authors = len(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 149682\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of authors:\", n_authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first build a weighted collaboration matrix $W \\in \\mathbb{R}^{n\\times n}$ (n := number of authors) such that for two authors $i$ and $j$:\n",
    "\n",
    "$$\n",
    "W_{ij} = \\sum_{p \\in papers} \\frac{\\delta^p_i \\delta^p_j}{n_p - 1} \n",
    "\\quad \\text{if} \\quad  i \\neq j \\quad\\quad \\text{and} \\quad\\quad\n",
    "W_{ii} = 0 \n",
    "$$\n",
    "\n",
    "where $n_p$ is the number of authors of paper $p$ and $\\delta^p_i$ = $\\mathbf{1}$($i \\in$ {authors of $p$}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_collab_weights = np.zeros((n_authors, n_authors)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_author_collabs = set()\n",
    "for paper in paper_authors:\n",
    "    # Create tuples of author collaborations for one paper\n",
    "    # itertools.combinations(p, r) creates r-length tuples, in sorted order, no repeated elements\n",
    "    # e.g. : list(itertools.combinations('ABC', 2)) >>> [('A', 'B'), ('A', 'B'), ('B', 'C')] \n",
    "    authors = paper_authors[paper]\n",
    "    author_collabs = list(itertools.combinations(authors, r=2))\n",
    "    all_author_collabs |= set(author_collabs)\n",
    "    for author_1, author_2 in author_collabs:\n",
    "        author_collab_weights[author_1, author_2] += 1/(len(authors)-1)\n",
    "        author_collab_weights[author_2, author_1] += 1/(len(authors)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556344\n",
      "529595\n"
     ]
    }
   ],
   "source": [
    "print(len(all_author_collabs))\n",
    "# We sort each pair of citation because we consider  that \n",
    "# a citation (author_1, author_2) is the same as a citation (author_2, author_1)\n",
    "all_author_collabs = list(map(sorted, all_author_collabs))\n",
    "# The result of sorted is a list so we put it back as a tuple\n",
    "all_author_collabs = set(map(tuple, all_author_collabs))\n",
    "print(len(all_author_collabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the collaborations in a file where each line 'author_1,author_2,n_collabs'\n",
    "# means that author_1 and author_2 co-authored n_collabs papers\n",
    "with open(\"../data/authors_processed/author_collab_edgelist.txt\", 'w+') as f:\n",
    "    for (author_1, author_2) in all_author_collabs:\n",
    "        weight = author_collab_weights[author_1, author_2]\n",
    "        f.write(f\"{author_1},{author_2},{round(weight,2)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Features of the author collaboration network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed_data/id2author.txt\", 'r') as f:\n",
    "    n_authors = len(f.readlines())\n",
    "\n",
    "# author collaboration graph\n",
    "G_author_collab = nx.read_weighted_edgelist(\n",
    "    '../data/processed_data/author_collab_edgelist.txt',\n",
    "    delimiter=',', \n",
    "    nodetype=int,\n",
    ")\n",
    "\n",
    "# There are authors who never co-authored a paper \n",
    "# these authors don't have edges (no collaboration) in the graph\n",
    "# so we have to add them \n",
    "# (we give all authors as paramater, the ones that don't exist yet will be added as single nodes)\n",
    "G_author_collab.add_nodes_from(range(n_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G_author_collab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0f0283ebac58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of nodes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_author_collab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of edges:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_author_collab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G_author_collab' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Number of nodes:\", len(G_author_collab.nodes()))\n",
    "print(\"Number of edges:\", len(G_author_collab.edges()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c13f75b521158b36ba3ff4ac87dceddef9f3d5f34c1f5e4e80e856c73bb49853"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
